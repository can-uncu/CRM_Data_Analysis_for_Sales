import pandas as pd
import numpy as np
from sqlalchemy import create_engine
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# PostgreSQL BaÄŸlantÄ±sÄ±
engine = create_engine("postgresql://postgres:admin@localhost:6543/Data Source")

# TablolarÄ± YÃ¼kle
accounts = pd.read_sql("SELECT * FROM public.accounts", engine)
sales_pipeline = pd.read_sql("SELECT * FROM public.sales_pipeline", engine)
products = pd.read_sql("SELECT * FROM public.products", engine)
sales_teams = pd.read_sql("SELECT * FROM public.sales_teams", engine)

# Tarih kolonlarÄ±nÄ± datetime'a Ã§evir
sales_pipeline['engage_date'] = pd.to_datetime(sales_pipeline['engage_date'])
sales_pipeline['close_date'] = pd.to_datetime(sales_pipeline['close_date'])
accounts['year_established'] = pd.to_numeric(accounts['year_established'], errors='coerce')

print("="*80)
print("CRM VERÄ° ANALÄ°ZÄ° SONUÃ‡LARI")
print("="*80)

# ============================================================================
# 1. RFM ANALÄ°ZÄ° (Recency, Frequency, Monetary)
# ============================================================================
print("\nğŸ“Š 1. RFM ANALÄ°ZÄ°")
print("-"*80)

# Won olan satÄ±ÅŸlarÄ± filtrele
won_deals = sales_pipeline[sales_pipeline['is_won'] == 1].copy()

# Her hesap iÃ§in RFM metrikleri
current_date = pd.Timestamp.now()
rfm = won_deals.groupby('account_id').agg({
    'close_date': lambda x: (current_date - x.max()).days,  # Recency
    'opportunity_id': 'count',  # Frequency
    'close_value': 'sum'  # Monetary
}).reset_index()

rfm.columns = ['account_id', 'recency', 'frequency', 'monetary']

# RFM Skorlama (1-5 arasÄ±) - GÃ¼venli skor hesaplama
def safe_qcut(series, q, labels, reverse=False):
    try:
        if reverse:
            return pd.qcut(series, q, labels=labels, duplicates='drop')
        else:
            return pd.qcut(series.rank(method='first'), q, labels=labels, duplicates='drop')
    except:
        # EÄŸer qcut baÅŸarÄ±sÄ±z olursa, percentile bazlÄ± skorlama yap
        if reverse:
            bins = [-np.inf, *np.percentile(series, [20, 40, 60, 80]), np.inf]
        else:
            bins = [-np.inf, *np.percentile(series, [20, 40, 60, 80]), np.inf]
        return pd.cut(series, bins=bins, labels=labels[:len(bins)-1], include_lowest=True)

rfm['r_score'] = safe_qcut(rfm['recency'], 5, [5,4,3,2,1], reverse=True)
rfm['f_score'] = safe_qcut(rfm['frequency'], 5, [1,2,3,4,5])
rfm['m_score'] = safe_qcut(rfm['monetary'], 5, [1,2,3,4,5])

rfm['rfm_score'] = rfm['r_score'].astype(str) + rfm['f_score'].astype(str) + rfm['m_score'].astype(str)

# Segmentasyon
def rfm_segment(row):
    score = int(row['r_score']) + int(row['f_score']) + int(row['m_score'])
    if score >= 13:
        return 'Champions'
    elif score >= 10:
        return 'Loyal Customers'
    elif score >= 7:
        return 'Potential Loyalists'
    elif score >= 5:
        return 'At Risk'
    else:
        return 'Lost'

rfm['segment'] = rfm.apply(rfm_segment, axis=1)

print(f"âœ… Toplam Analiz Edilen MÃ¼ÅŸteri: {len(rfm)}")
print(f"\nSegment DaÄŸÄ±lÄ±mÄ±:")
print(rfm['segment'].value_counts())
print(f"\nOrtalama RFM Metrikleri:")
print(f"  â€¢ Recency (Son alÄ±ÅŸveriÅŸten itibaren gÃ¼n): {rfm['recency'].mean():.0f}")
print(f"  â€¢ Frequency (AlÄ±ÅŸveriÅŸ sayÄ±sÄ±): {rfm['frequency'].mean():.1f}")
print(f"  â€¢ Monetary (Toplam deÄŸer): ${rfm['monetary'].mean():,.2f}")

# ============================================================================
# 2. CHURN ANALÄ°ZÄ° (MÃ¼ÅŸteri KaybÄ±)
# ============================================================================
print("\n\nğŸ“Š 2. CHURN ANALÄ°ZÄ°")
print("-"*80)

# Son 180 gÃ¼n iÃ§inde alÄ±ÅŸveriÅŸ yapmayan mÃ¼ÅŸteriler churn olarak kabul edilir
churn_threshold_days = 180
rfm['is_churned'] = rfm['recency'] > churn_threshold_days

churn_rate = (rfm['is_churned'].sum() / len(rfm)) * 100
active_customers = len(rfm[~rfm['is_churned']])
churned_customers = len(rfm[rfm['is_churned']])

print(f"âœ… Churn OranÄ±: {churn_rate:.2f}%")
print(f"  â€¢ Aktif MÃ¼ÅŸteri: {active_customers}")
print(f"  â€¢ KayÄ±p MÃ¼ÅŸteri: {churned_customers}")
print(f"  â€¢ Churn EÅŸik DeÄŸeri: {churn_threshold_days} gÃ¼n")

# Churn risk faktÃ¶rleri
churn_analysis = rfm.groupby('is_churned').agg({
    'frequency': 'mean',
    'monetary': 'mean',
    'recency': 'mean'
})
print(f"\nChurn Risk FaktÃ¶rleri:")
print(churn_analysis)

# ============================================================================
# 3. CLV (Customer Lifetime Value)
# ============================================================================
print("\n\nğŸ“Š 3. CLV (Customer Lifetime Value)")
print("-"*80)

# BasitleÅŸtirilmiÅŸ CLV: Ortalama alÄ±ÅŸveriÅŸ deÄŸeri * AlÄ±ÅŸveriÅŸ sÄ±klÄ±ÄŸÄ± * MÃ¼ÅŸteri Ã¶mrÃ¼
avg_purchase_value = rfm['monetary'] / rfm['frequency']
purchase_frequency = rfm['frequency']
customer_lifespan_years = 3  # VarsayÄ±lan mÃ¼ÅŸteri Ã¶mrÃ¼

rfm['clv'] = avg_purchase_value * purchase_frequency * customer_lifespan_years

print(f"âœ… Ortalama CLV: ${rfm['clv'].mean():,.2f}")
print(f"  â€¢ En yÃ¼ksek CLV: ${rfm['clv'].max():,.2f}")
print(f"  â€¢ En dÃ¼ÅŸÃ¼k CLV: ${rfm['clv'].min():,.2f}")
print(f"  â€¢ Medyan CLV: ${rfm['clv'].median():,.2f}")

print(f"\nCLV Segmentasyonu:")
rfm['clv_segment'] = pd.qcut(rfm['clv'], 4, labels=['Low', 'Medium', 'High', 'Very High'], duplicates='drop')
print(rfm['clv_segment'].value_counts())

# ============================================================================
# 4. ARPU (Average Revenue Per User)
# ============================================================================
print("\n\nğŸ“Š 4. ARPU (Average Revenue Per User)")
print("-"*80)

total_revenue = won_deals['close_value'].sum()
total_customers = accounts['account_id'].nunique()
arpu = total_revenue / total_customers

print(f"âœ… ARPU: ${arpu:,.2f}")
print(f"  â€¢ Toplam Gelir: ${total_revenue:,.2f}")
print(f"  â€¢ Toplam MÃ¼ÅŸteri: {total_customers}")

# AylÄ±k ARPU trendi
won_deals['close_month'] = won_deals['close_date'].dt.to_period('M')
monthly_arpu = won_deals.groupby('close_month').agg({
    'close_value': 'sum',
    'account_id': 'nunique'
}).reset_index()
monthly_arpu['arpu'] = monthly_arpu['close_value'] / monthly_arpu['account_id']

print(f"\nSon 5 AyÄ±n ARPU Trendi:")
print(monthly_arpu.tail())

# ============================================================================
# 5. COHORT ANALÄ°ZÄ°
# ============================================================================
print("\n\nğŸ“Š 5. COHORT ANALÄ°ZÄ°")
print("-"*80)

# Ä°lk alÄ±ÅŸveriÅŸ tarihine gÃ¶re cohort oluÅŸtur
first_purchase = won_deals.groupby('account_id')['close_date'].min().reset_index()
first_purchase.columns = ['account_id', 'cohort_date']
first_purchase['cohort'] = first_purchase['cohort_date'].dt.to_period('M')

# Won deals ile birleÅŸtir
cohort_data = won_deals.merge(first_purchase[['account_id', 'cohort']], on='account_id')
cohort_data['order_period'] = cohort_data['close_date'].dt.to_period('M')

# Cohort'tan bu yana geÃ§en ay sayÄ±sÄ±
cohort_data['period_number'] = (cohort_data['order_period'] - cohort_data['cohort']).apply(lambda x: x.n)

# Cohort analizi tablosu
cohort_counts = cohort_data.groupby(['cohort', 'period_number'])['account_id'].nunique().reset_index()
cohort_pivot = cohort_counts.pivot(index='cohort', columns='period_number', values='account_id')

print(f"âœ… Cohort Tablosu OluÅŸturuldu")
print(f"  â€¢ Toplam Cohort: {len(cohort_pivot)}")
print(f"\nÄ°lk 5 Cohort'un Ä°lk 6 AyÄ±:")
print(cohort_pivot.iloc[:5, :6])

# ============================================================================
# 6. CONVERSION RATE (DÃ¶nÃ¼ÅŸÃ¼m OranÄ±)
# ============================================================================
print("\n\nğŸ“Š 6. CONVERSION RATE (DÃ¶nÃ¼ÅŸÃ¼m OranÄ±)")
print("-"*80)

total_opportunities = len(sales_pipeline)
won_opportunities = len(won_deals)
conversion_rate = (won_opportunities / total_opportunities) * 100

print(f"âœ… Genel DÃ¶nÃ¼ÅŸÃ¼m OranÄ±: {conversion_rate:.2f}%")
print(f"  â€¢ Toplam FÄ±rsat: {total_opportunities}")
print(f"  â€¢ KazanÄ±lan FÄ±rsat: {won_opportunities}")
print(f"  â€¢ Kaybedilen FÄ±rsat: {sales_pipeline['is_lost'].sum()}")

# Deal stage'e gÃ¶re dÃ¶nÃ¼ÅŸÃ¼m oranÄ±
stage_conversion = sales_pipeline.groupby('deal_stage').agg({
    'opportunity_id': 'count',
    'is_won': 'sum'
}).reset_index()
stage_conversion['conversion_rate'] = (stage_conversion['is_won'] / stage_conversion['opportunity_id']) * 100
stage_conversion = stage_conversion.sort_values('conversion_rate', ascending=False)

print(f"\nDeal Stage'e GÃ¶re DÃ¶nÃ¼ÅŸÃ¼m OranlarÄ±:")
print(stage_conversion[['deal_stage', 'conversion_rate']].to_string(index=False))

# Agent'a gÃ¶re dÃ¶nÃ¼ÅŸÃ¼m oranÄ±
agent_conversion = sales_pipeline.groupby('agent_id').agg({
    'opportunity_id': 'count',
    'is_won': 'sum'
}).reset_index()
agent_conversion['conversion_rate'] = (agent_conversion['is_won'] / agent_conversion['opportunity_id']) * 100
agent_conversion = agent_conversion.sort_values('conversion_rate', ascending=False)

print(f"\nEn Ä°yi 5 Agent DÃ¶nÃ¼ÅŸÃ¼m OranlarÄ±:")
print(agent_conversion.head()[['agent_id', 'conversion_rate']].to_string(index=False))

# ============================================================================
# 7. RETENTION RATE (Elde Tutma OranÄ±)
# ============================================================================
print("\n\nğŸ“Š 7. RETENTION RATE (Elde Tutma OranÄ±)")
print("-"*80)

# AylÄ±k retention hesaplama
retention_data = cohort_pivot.divide(cohort_pivot[0], axis=0) * 100

print(f"âœ… Retention Rate (YÃ¼zde Olarak):")
print(f"\nÄ°lk 5 Cohort'un Ä°lk 6 AyÄ±:")
print(retention_data.iloc[:5, :6].round(1))

avg_retention_month_1 = retention_data[1].mean() if 1 in retention_data.columns else 0
avg_retention_month_3 = retention_data[3].mean() if 3 in retention_data.columns else 0

print(f"\nOrtalama Retention OranlarÄ±:")
print(f"  â€¢ 1. Ay: {avg_retention_month_1:.1f}%")
print(f"  â€¢ 3. Ay: {avg_retention_month_3:.1f}%")

# ============================================================================
# 8. CORRELATION ANALÄ°ZÄ° (Ä°liÅŸki Analizi)
# ============================================================================
print("\n\nğŸ“Š 8. CORRELATION ANALÄ°ZÄ°")
print("-"*80)

# SayÄ±sal kolonlarÄ± seÃ§
numeric_accounts = accounts.select_dtypes(include=[np.number])
numeric_pipeline = sales_pipeline.select_dtypes(include=[np.number])

# Account verileri ile satÄ±ÅŸ deÄŸeri korelasyonu
account_sales = won_deals.groupby('account_id')['close_value'].sum().reset_index()
account_merged = accounts.merge(account_sales, on='account_id', how='inner')

correlation_features = ['employees', 'revenue', 'year_established', 'close_value']
available_features = [f for f in correlation_features if f in account_merged.columns]

if len(available_features) > 1:
    corr_matrix = account_merged[available_features].corr()
    
    print(f"âœ… Korelasyon Matrisi:")
    print(corr_matrix.round(3))
    
    print(f"\nÃ–nemli Korelasyonlar (close_value ile):")
    if 'close_value' in corr_matrix:
        close_value_corr = corr_matrix['close_value'].drop('close_value').sort_values(ascending=False)
        print(close_value_corr)

# ============================================================================
# 9. REGRESSION ANALÄ°ZÄ° (Revenue Tahmini)
# ============================================================================
print("\n\nğŸ“Š 9. REGRESSION ANALÄ°ZÄ°")
print("-"*80)

if 'employees' in account_merged.columns and 'revenue' in account_merged.columns:
    # NaN deÄŸerleri temizle
    regression_data = account_merged[['employees', 'revenue', 'close_value']].dropna()
    
    if len(regression_data) > 10:
        # Linear Regression (employees -> close_value)
        slope, intercept, r_value, p_value, std_err = stats.linregress(
            regression_data['employees'], 
            regression_data['close_value']
        )
        
        print(f"âœ… Ã‡alÄ±ÅŸan SayÄ±sÄ± vs SatÄ±ÅŸ DeÄŸeri Regresyonu:")
        print(f"  â€¢ R-squared: {r_value**2:.3f}")
        print(f"  â€¢ Slope (EÄŸim): {slope:.2f}")
        print(f"  â€¢ P-value: {p_value:.4f}")
        print(f"  â€¢ Ä°statistiksel AnlamlÄ±lÄ±k: {'Evet' if p_value < 0.05 else 'HayÄ±r'}")
        
        # Revenue vs close_value
        slope2, intercept2, r_value2, p_value2, std_err2 = stats.linregress(
            regression_data['revenue'], 
            regression_data['close_value']
        )
        
        print(f"\n  Account Revenue vs SatÄ±ÅŸ DeÄŸeri Regresyonu:")
        print(f"  â€¢ R-squared: {r_value2**2:.3f}")
        print(f"  â€¢ Slope (EÄŸim): {slope2:.4f}")
        print(f"  â€¢ P-value: {p_value2:.4f}")

# ============================================================================
# 10. ROI ANALÄ°ZÄ° (Return on Investment)
# ============================================================================
print("\n\nğŸ“Š 10. ROI ANALÄ°ZÄ°")
print("-"*80)

# ÃœrÃ¼n bazlÄ± ROI (sales_price vs close_value)
product_sales = won_deals.merge(products, on='product_id', how='left')

if 'sales_price' in product_sales.columns:
    roi_analysis = product_sales.groupby('product').agg({
        'sales_price': 'sum',
        'close_value': 'sum'
    }).reset_index()
    
    roi_analysis['roi'] = ((roi_analysis['close_value'] - roi_analysis['sales_price']) / 
                           roi_analysis['sales_price'] * 100)
    roi_analysis = roi_analysis.sort_values('roi', ascending=False)
    
    print(f"âœ… ÃœrÃ¼n BazlÄ± ROI Analizi:")
    print(roi_analysis.to_string(index=False))
    
    avg_roi = roi_analysis['roi'].mean()
    print(f"\nOrtalama ROI: {avg_roi:.2f}%")

# ============================================================================
# 11. SEGMENTATION (MÃ¼ÅŸteri Segmentasyonu)
# ============================================================================
print("\n\nğŸ“Š 11. CUSTOMER SEGMENTATION")
print("-"*80)

# Sector bazlÄ± segmentasyon
if 'sector' in accounts.columns:
    sector_performance = accounts.merge(
        won_deals.groupby('account_id')['close_value'].sum().reset_index(),
        on='account_id',
        how='left'
    )
    
    sector_stats = sector_performance.groupby('sector').agg({
        'account_id': 'count',
        'close_value': ['sum', 'mean']
    }).round(2)
    
    sector_stats.columns = ['Customer_Count', 'Total_Revenue', 'Avg_Revenue']
    sector_stats = sector_stats.sort_values('Total_Revenue', ascending=False)
    
    print(f"âœ… SektÃ¶r BazlÄ± Segmentasyon:")
    print(sector_stats)

# Company size segmentasyonu
if 'employees' in accounts.columns:
    accounts['company_size'] = pd.cut(
        accounts['employees'],
        bins=[0, 50, 200, 1000, float('inf')],
        labels=['Small', 'Medium', 'Large', 'Enterprise']
    )
    
    size_performance = accounts.merge(
        won_deals.groupby('account_id')['close_value'].sum().reset_index(),
        on='account_id',
        how='left'
    )
    
    size_stats = size_performance.groupby('company_size').agg({
        'account_id': 'count',
        'close_value': ['sum', 'mean']
    }).round(2)
    
    print(f"\nâœ… Åirket BÃ¼yÃ¼klÃ¼ÄŸÃ¼ BazlÄ± Segmentasyon:")
    print(size_stats)

# ============================================================================
# 12. SALES TEAM PERFORMANCE
# ============================================================================
print("\n\nğŸ“Š 12. SALES TEAM PERFORMANCE")
print("-"*80)

team_performance = sales_pipeline.merge(sales_teams, on='agent_id', how='left')

team_stats = team_performance.groupby('manager').agg({
    'opportunity_id': 'count',
    'close_value': 'sum',
    'is_won': 'sum'
}).reset_index()

team_stats['conversion_rate'] = (team_stats['is_won'] / team_stats['opportunity_id'] * 100).round(2)
team_stats['avg_deal_size'] = (team_stats['close_value'] / team_stats['is_won']).round(2)
team_stats = team_stats.sort_values('close_value', ascending=False)

print(f"âœ… Manager BazlÄ± Performans:")
print(team_stats.to_string(index=False))

print("\n" + "="*80)
print("ANALÄ°Z TAMAMLANDI!")
print("="*80)